{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "utils.add_dense_correspondence_to_python_path()\n",
    "\n",
    "import dense_correspondence\n",
    "from dense_correspondence.evaluation.evaluation import *\n",
    "import dense_correspondence.correspondence_tools.correspondence_plotter as correspondence_plotter\n",
    "import dense_correspondence.correspondence_tools.correspondence_finder as correspondence_finder\n",
    "from dense_correspondence.correspondence_tools.correspondence_finder import random_sample_from_masked_image, pinhole_projection_image_to_world\n",
    "from dense_correspondence.dataset.dense_correspondence_dataset_masked import ImageType\n",
    "from dense_correspondence.network.dense_correspondence_network import DenseCorrespondenceNetwork\n",
    "import dense_correspondence.evaluation.plotting as dc_plotting\n",
    "import glob\n",
    "from scipy import misc\n",
    "import pickle\n",
    "from os.path import basename\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--name',  type=str, default=\"cup_bottlesauce_elephant_cat_pear_rgb_unit_16\")\n",
    "parser.add_argument('--experiment', type=str, default=\"classification\")\n",
    "parser.add_argument('--savefile', type=str, default=\"ycb_results.pkl\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "utils.set_cuda_visible_devices([1]) # use this to manually set CUDA_VISIBLE_DEVICES\n",
    "\n",
    "config_filename = os.path.join(utils.getDenseCorrespondenceSourceDir(), 'config',\n",
    "                               'dense_correspondence', 'evaluation', 'evaluation.yaml')\n",
    "config = utils.getDictFromYamlFilename(config_filename)\n",
    "dce = DenseCorrespondenceEvaluation(config)\n",
    "DCE = DenseCorrespondenceEvaluation\n",
    "dcn = dce.load_network_from_config(args.name)\n",
    "print(\"Loaded network. \")\n",
    "dataset = dcn.load_training_dataset()\n",
    "print(\"Loaded dataset. \")\n",
    "camera_intrinsics = dataset.get_camera_intrinsics(\"elephant\")\n",
    "\n",
    "\n",
    "def match_index_and_norm_diff(query, features, cond=None):\n",
    "    \"\"\"\n",
    "    Assumes that query and features both have shape (N, D).\n",
    "    query: ndarray (D,)\n",
    "    features: ndarray (N, D)\n",
    "    \"\"\"\n",
    "\n",
    "    if cond is None:\n",
    "        norm_diffs = np.sqrt(np.sum(np.square(features - query), axis=1))\n",
    "\n",
    "    elif cond == \"ppf\":\n",
    "        f1 = features[:, 1:]\n",
    "        D = f1.shape[1]\n",
    "        f2 = np.concatenate((f1[:, D//2:], f1[:, :D//2]), axis=1)\n",
    "\n",
    "        norm_diffs1 = np.sqrt(np.sum(np.square(f1 - query[1:]), axis=1))\n",
    "        norm_diffs2 = np.sqrt(np.sum(np.square(f2 - query[1:]), axis=1))\n",
    "        norm_diffs = np.minimum(norm_diffs1, norm_diffs2)\n",
    "\n",
    "        feature_cond = features[:, 0]\n",
    "        query_cond = query[0]\n",
    "        mask = np.logical_and(feature_cond > 5./7*query_cond, feature_cond < 9./7*query_cond).astype(np.float)\n",
    "        norm_diffs = mask * norm_diffs + np.nan_to_num((1-mask) * float(\"inf\") * np.ones(norm_diffs.shape))\n",
    "    else:\n",
    "        assert 1 == 0\n",
    "\n",
    "    best_match_index = np.argmin(norm_diffs)\n",
    "    best_match_diff = norm_diffs[best_match_index]\n",
    "    result = np.array([best_match_index, best_match_diff])\n",
    "\n",
    "    #         candidate_indices = np.argwhere(np.logical_and(ppfs[:,0] > 5/7*ppf_target[0], ppfs[:,0] < 9/7*ppf_target[0])).T[0]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def simple_match(f1, f2, cond=None):\n",
    "    \"\"\"\n",
    "    Simple brute force matching between features1 and features2.\n",
    "    f1: ndarray of shape (N, ... )\n",
    "    f2: ndarray of shape (N, ....)\n",
    "    fn: None, \"ppf\"\n",
    "    Returns indices of matches. Also does some filtering\n",
    "    to make sure that the best match of f1 is the best match of f2.\n",
    "    \"\"\"\n",
    "\n",
    "    f1 = f1.reshape((f1.shape[0], -1))\n",
    "    f2 = f2.reshape((f2.shape[0], -1))\n",
    "\n",
    "    f1_matches = np.apply_along_axis(lambda x: match_index_and_norm_diff(x, f2, cond), 1, f1)\n",
    "    f2_matches = np.apply_along_axis(lambda x: match_index_and_norm_diff(x, f1, cond), 1, f2)\n",
    "\n",
    "    best_matches = []\n",
    "    for i in range(f1_matches.shape[0]):\n",
    "        norm_diff = f1_matches[i, 1]\n",
    "        best_match_index = int(f1_matches[i, 0])\n",
    "        if f2_matches[best_match_index, 0] == i: # If they're the best matches of each other\n",
    "            best_matches.append((i, best_match_index, norm_diff))\n",
    "\n",
    "    return best_matches\n",
    "\n",
    "\n",
    "def run_dcn_on_image(dcn, dataset, img):\n",
    "    \"\"\"\n",
    "    Run DCN on PIL img. use of dataset is a hack, just need to ge the descriptor image stats\n",
    "    which actually just uses a constant for std and mean.\n",
    "    \"\"\"\n",
    "    rgb_a_tensor = dataset.rgb_image_to_tensor(img)\n",
    "    res_a = dcn.forward_single_image_tensor(rgb_a_tensor).data.cpu().numpy()\n",
    "    descriptor_image_stats = dcn.descriptor_image_stats\n",
    "    res_a_norm = dc_plotting.normalize_descriptor(res_a, descriptor_image_stats[\"mask_image\"])\n",
    "    return res_a_norm\n",
    "\n",
    "def compute_PPF_feature(uv_A, uv_B, img, des, camera_intrinsics):\n",
    "    \"\"\"\n",
    "    Computes PPF feature from uv_A and uv_B. These are in UV (openCV) format.\n",
    "    Camera intrinsics should be in one of the first cells.\n",
    "\n",
    "    img is the input \"depth rgb\" image. Bc it was generated with img = actual_depth / 0.2,\n",
    "    the actual depth is img * 0.2\n",
    "\n",
    "    Descriptor is [weight * distance, des_A...., desB....]\n",
    "    # \"\"\"\n",
    "    # print(img.shape)\n",
    "    # print(np.sum(img[:, :, 0] - img[:, :, 1]))\n",
    "    #\n",
    "    #\n",
    "    # assert len(img.shape) == 2 # make sure that this is a depth image!\n",
    "\n",
    "#     if uv_B[0] < uv_A[0]:\n",
    "#         uv_A, uv_B = uv_B, uv_A\n",
    "#     elif uv_B[0] == uv_A[0] and uv_B[1] < uv_A[1]:\n",
    "#         uv_A, uv_B = uv_B, uv_A\n",
    "\n",
    "    # !! HACK !!\n",
    "    # NEED TO CHECK IF IT's 0-255 or 0-1\n",
    "    depth_A = img[uv_A[1], uv_A[0]] / 255.\n",
    "    depth_B = img[uv_B[1], uv_B[1]] / 255.\n",
    "    des_A = des[uv_A[1], uv_A[0], :]\n",
    "    des_B = des[uv_B[1], uv_B[0], :]\n",
    "\n",
    "    pos_in_camera_frameA = pinhole_projection_image_to_world(uv_A, depth_A, camera_intrinsics.K)\n",
    "    pos_in_camera_frameB = pinhole_projection_image_to_world(uv_B, depth_B, camera_intrinsics.K)\n",
    "\n",
    "    distance = np.sqrt(np.sum((pos_in_camera_frameA - pos_in_camera_frameB)**2))\n",
    "#     dist = lambda x, y: np.sqrt((x[0]-y[0])**2 + (x[1]-y[1])**2)\n",
    "#     distance = dist(uv_A, uv_B)\n",
    "    ppf = np.concatenate((np.array([distance]), des_A, des_B))\n",
    "    des_distance = np.sqrt(np.sum((des_A - des_B)**2))\n",
    "    return ppf, des_distance\n",
    "\n",
    "\n",
    "def generate_PPF_samples(img, des, mask, num_samples=5):\n",
    "    \"\"\"Generate np.array of shape (N**2 x PPF_dim) sample features.\n",
    "    Returns list of (UV_A, UV_B) samples.\n",
    "    \"\"\"\n",
    "    dist = lambda x, y: np.sqrt((x[0]-y[0])**2 + (x[1]-y[1])**2)\n",
    "    mask = mask[:, :, 0].astype(np.int)\n",
    "    sampled_idx_list = random_sample_from_masked_image(mask, num_samples)\n",
    "\n",
    "    # If the list is empty, return an empty list\n",
    "    if len(sampled_idx_list) == 0:\n",
    "        return dataframe_list\n",
    "\n",
    "    ppf_lst = []\n",
    "    coord_lst = []\n",
    "    des_distances = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        for j in range(i+1, num_samples):\n",
    "            uv_A = [sampled_idx_list[1][i], sampled_idx_list[0][i]]\n",
    "            uv_B = [sampled_idx_list[1][j], sampled_idx_list[0][j]]\n",
    "            if dist(uv_A, uv_B) > 20: # Basic: Increase pixel distance. # !!! this might be a reason for failure for small objects\n",
    "#                                       # TODO: Increase physical spatial difference\n",
    "#                                       # TODO: Increase feature space difference\n",
    "                coord_lst.append((uv_A, uv_B))\n",
    "                ppf_feature, des_distance = compute_PPF_feature(uv_A, uv_B, img, des, camera_intrinsics)\n",
    "                des_distances.append(des_distance)\n",
    "                ppf_lst.append(ppf_feature)\n",
    "\n",
    "    ppf_lst = np.array(ppf_lst)\n",
    "    coord_lst = np.array(coord_lst)\n",
    "    des_distances = np.array(des_distances)\n",
    "    best_distances = np.argsort(des_distances)[-(len(des_distances)//3):] # !!!!! HACK\n",
    "    return ppf_lst[best_distances], coord_lst[best_distances]\n",
    "\n",
    "# key: \"banana\", value: [('object1', norm), ('object2', norm)]\n",
    "results = {}\n",
    "num_in_top_5 = 0\n",
    "target_files = sorted(glob.glob(\"/nfs/diskstation/objects/meshes/ycb/*\"))\n",
    "all_heap_paths = sorted(glob.glob(\"/nfs/diskstation/objects/meshes/ycb/*\"))\n",
    "target_ppfs = {}\n",
    "\n",
    "def classification_from_heap(heap_name):\n",
    "    \"\"\"\n",
    "    For every heap image, get the top N matches from target image.\n",
    "    \"\"\"\n",
    "    global num_in_top_5\n",
    "    print(\"===========================ON HEAP {}========================\".format(heap_name))\n",
    "    heap_img = Image.open(\"images/ycb_heap_0/{}/rgb.png\".format(heap_name)).convert('RGB')\n",
    "    heap_depth = misc.imread(\"images/ycb_heap_0/{}/depth_unscaled.png\".format(heap_name))\n",
    "    heap_mask = np.load(\"images/ycb_heap_0/{}/mask.npy\".format(heap_name)).astype(np.bool)\n",
    "    heap = np.array(heap_img)\n",
    "    heap_descriptors = run_dcn_on_image(dcn, dataset, heap_img)\n",
    "    ppf_heap, _ = generate_PPF_samples(heap_depth, heap_descriptors, heap_mask, 100)\n",
    "    cur_results = []\n",
    "\n",
    "    for mesh_path in target_files:\n",
    "        target_name = basename(mesh_path).split(\".\")[0]\n",
    "        print(\"Testing target:\", target_name)\n",
    "        smallest_norm = float('inf')\n",
    "\n",
    "        cur_ppfs = []\n",
    "\n",
    "        for i in range(6):\n",
    "            if target_name in target_ppfs:\n",
    "                ppf_t = target_ppfs[target_name][i]\n",
    "            else:\n",
    "                target_mask = np.load(\"images/ycb_targets/{}/mask_{}.npy\".format(target_name, i)).astype(np.bool)\n",
    "                target_depth = misc.imread(\"images/ycb_targets/{}/depth_unscaled_{}.png\".format(target_name, i))\n",
    "                target_img = Image.open(\"images/ycb_targets/{}/rgb_{}.png\".format(target_name, i)).convert('RGB')\n",
    "                target_descriptors = run_dcn_on_image(dcn, dataset, target_img)\n",
    "\n",
    "                ppf_t, _ = generate_PPF_samples(target_depth, target_descriptors, target_mask, 100)\n",
    "                cur_ppfs.append(ppf_t)\n",
    "\n",
    "            # Generate ppfs for each object in the heap\n",
    "            best_matches_lst = simple_match(ppf_t, ppf_heap, cond=\"ppf\")\n",
    "            if len(best_matches_lst) > 0:\n",
    "                distances = [match[2] for match in best_matches_lst]\n",
    "                distances = np.array(sorted(distances)[:10])\n",
    "                smallest_norm = min(smallest_norm, np.mean(distances))\n",
    "        cur_results.append((target_name, smallest_norm))\n",
    "        if target_name not in target_ppfs:\n",
    "            target_ppfs[target_name] = cur_ppfs\n",
    "\n",
    "        # print(cur_results)\n",
    "    cur_results = sorted(cur_results, key = lambda x: x[1])\n",
    "    results[heap_name] = cur_results\n",
    "    with open(args.savefile, 'wb') as handle:\n",
    "        pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(cur_results)\n",
    "    # for i in range(5):\n",
    "    #     if cur_results[i][0] == heap_name:\n",
    "    #         num_in_top_5 += 1\n",
    "    #         break\n",
    "\n",
    "def heapsearch_from_target(target_name):\n",
    "    target_ppfs = []\n",
    "    cur_results = []\n",
    "    print(\"===========================ON TARGET {}========================\".format(target_name))\n",
    "\n",
    "    for i in range(6):\n",
    "        target_mask = np.load(\"images/ycb_targets/{}/mask_{}.npy\".format(target_name, i)).astype(np.bool)\n",
    "        target_depth = misc.imread(\"images/ycb_targets/{}/depth_unscaled_{}.png\".format(target_name, i))\n",
    "        target_img = Image.open(\"images/ycb_targets/{}/rgb_{}.png\".format(target_name, i)).convert('RGB')\n",
    "        target_descriptors = run_dcn_on_image(dcn, dataset, target_img)\n",
    "        ppf_t, _ = generate_PPF_samples(target_depth, target_descriptors, target_mask, 100)\n",
    "        target_ppfs.append(ppf_t)\n",
    "\n",
    "    for heap_path in all_heap_paths:\n",
    "        print(\"Testing heap: {}\".format(heap_path))\n",
    "        heap_name = basename(heap_path).split(\".\")[0]\n",
    "        heap_img = Image.open(\"images/ycb_heap_0/{}/rgb.png\".format(heap_name)).convert('RGB')\n",
    "        heap_depth = misc.imread(\"images/ycb_heap_0/{}/depth_unscaled.png\".format(heap_name))\n",
    "\n",
    "        heap_mask = np.load(\"images/ycb_heap_0/{}/mask.npy\".format(heap_name)).astype(np.bool)\n",
    "        heap = np.array(heap_img)\n",
    "        heap_descriptors = run_dcn_on_image(dcn, dataset, heap_img)\n",
    "        ppf_heap, _ = generate_PPF_samples(heap_depth, heap_descriptors, heap_mask, 100)\n",
    "\n",
    "        smallest_norm = float('inf')\n",
    "        for i in range(6):\n",
    "            ppf_t = target_ppfs[i]\n",
    "            best_matches_lst = simple_match(ppf_t, ppf_heap, cond=\"ppf\")\n",
    "            if len(best_matches_lst) > 0:\n",
    "                distances = [match[2] for match in best_matches_lst]\n",
    "                distances = np.array(sorted(distances)[:10])\n",
    "                smallest_norm = min(smallest_norm, np.mean(distances))\n",
    "        cur_results.append((heap_name, smallest_norm))\n",
    "    results[target_name] = sorted(cur_results, key = lambda x: x[1])\n",
    "    with open(args.savefile, 'wb') as handle:\n",
    "        pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.experiment == \"classification\":\n",
    "    print(\"Running classification\")\n",
    "    for heap_path in all_heap_paths:\n",
    "        heap_name = basename(heap_path).split(\".\")[0]\n",
    "        classification_from_heap(heap_name)\n",
    "elif args.experiment == \"heapsearch\":\n",
    "    print(\"Running heapsearch\")\n",
    "    for target_path in target_files:\n",
    "        target_name = basename(target_path).split(\".\")[0]\n",
    "        heapsearch_from_target(target_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
